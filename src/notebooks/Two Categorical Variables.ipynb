{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSOCIATIONS: TWO CATEGORICAL VARIABLES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lesson, we will cover ways of examining an association between two categorical variables.\n",
    "\n",
    "As an example, we'll explore a sample of data from the Narcissistic Personality Inventory (NPI-40), a personality test with 40 questions about personal preferences and self-view. There are two possible responses to each question. The sample we'll be working with contains responses to the following:\n",
    "\n",
    "- **influence**: yes = I have a natural talent for influencing people; no = I am not good at influencing people.\n",
    "- **blend_in**: yes = I prefer to blend in with the crowd; no = I like to be the center of attention.\n",
    "- **special**: yes = I think I am a special person; no = I am no better or worse than most people.\n",
    "- **leader**: yes = I see myself as a good leader; no = I am not sure if I would make a good leader.\n",
    "- **authority**: yes = I like to have authority over other people; no = I don't mind following orders.\n",
    "\n",
    "As you might guess, responses to some of these questions are associated. For example, if we know whether someone views themself as a good leader, we may also find that they're more likely to like having authority. In this lesson we'll learn how to assess whether an association exists between any two of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  influence blend_in special leader authority\n",
      "0        no      yes     yes    yes       yes\n",
      "1        no      yes      no     no        no\n",
      "2       yes       no     yes    yes       yes\n",
      "3       yes       no      no    yes       yes\n",
      "4       yes      yes      no    yes        no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "npi = pd.read_csv(\"npi_sample.csv\")\n",
    "\n",
    "print(npi.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency Tables: Frequencies\n",
    "\n",
    "Contingency tables, also known as two-way tables or cross-tabulations, are useful for summarizing two variables at the same time. For example, suppose we are interested in understanding whether there is an association between influence (whether a person thinks they have a talent for influencing people) and leader (whether they see themself as a leader). We can use the crosstab function from pandas to create a contingency table:\n",
    "\n",
    "```python\n",
    "influence_leader_freq = pd.crosstab(npi.influence, npi.leader)\n",
    "print(influence_leader_freq)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "\n",
    "```bash\n",
    "leader       no   yes\n",
    "influence            \n",
    "no         3015  1293\n",
    "yes        2360  4429\n",
    "```\n",
    "\n",
    "This table tells us the number of people who gave each possible combination of responses to these two questions. For example, 2360 people said that they do not see themselves as a leader but have a talent for influencing people.\n",
    "\n",
    "To assess whether there is an association between these two variables, we need to ask whether information about one variable gives us information about the other. In this example, we see that among people who don't see themselves as a leader (the first column), a larger number (3015) don't think they have a talent for influencing people. Meanwhile, among people who do see themselves as a leader (the second column), a larger number (4429) do think they have a talent for influencing people.\n",
    "\n",
    "So, if we know how someone responded to the leadership question, we have some information about how they are likely to respond to the influence question. This suggests that the variables are associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authority    no   yes\n",
      "special              \n",
      "no         4069  1905\n",
      "yes        2229  2894\n"
     ]
    }
   ],
   "source": [
    "special_authority_freq = pd.crosstab(npi.special, npi.authority)\n",
    "print(special_authority_freq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contingency Tables: Proportions\n",
    "\n",
    "In the previous exercise, we looked at an association between the influence and leader questions using a contingency table of frequencies. However, sometimes it's helpful to convert those frequencies to proportions. We can accomplish this simply by dividing the all the frequencies in a contingency table by the total number of observations (the sum of the frequencies):\n",
    "\n",
    "influence_leader_freq = pd.crosstab(npi.influence, npi.leader)\n",
    "influence_leader_prop = influence_leader_freq/len(npi)\n",
    "print(influence_leader_prop)\n",
    "Output:\n",
    "\n",
    "```bash\n",
    "leader           no       yes\n",
    "influence                    \n",
    "no         0.271695  0.116518\n",
    "yes        0.212670  0.399117\n",
    "```\n",
    "\n",
    "The resulting contingency table makes it slightly easier to compare the proportion of people in each category. For example, we see that the two largest proportions in the table (.399 and .271) are in the yes/yes and no/no cells of the table. We can also see that almost 40% of the surveyed population (by far the largest proportion) both see themselves as leaders and think they have a talent for influencing people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authority        no       yes\n",
      "special                      \n",
      "no         0.366676  0.171668\n",
      "yes        0.200865  0.260791\n"
     ]
    }
   ],
   "source": [
    "special_authority_freq = pd.crosstab(npi.special, npi.authority)\n",
    "\n",
    "# save the table of proportions as special_authority_prop:\n",
    "special_authority_prop = special_authority_freq/len(npi)\n",
    "\n",
    "# print out special_authority_prop\n",
    "print(special_authority_prop)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Proportions\n",
    "\n",
    "In the previous exercises, we looked at an association between the influence and leader questions using a contingency table. We saw some evidence of an association between these questions.\n",
    "\n",
    "Now, let's take a moment to think about what the tables would look like if there were no association between the variables. Our first instinct may be that there would be .25 (25%) of the data in each of the four cells of the table, but that is not the case. Let's take another look at our contingency table.\n",
    "\n",
    "```bash\n",
    "leader           no       yes\n",
    "influence                    \n",
    "no         0.271695  0.116518\n",
    "yes        0.212670  0.399117\n",
    "```\n",
    "\n",
    "We might notice that the bottom row, which corresponds to people who think they have a talent for influencing people, accounts for 0.213 + 0.399 = 0.612 (or 61.2%) of surveyed people â€” more than half! This means that we can expect higher proportions in the bottom row, regardless of whether the questions are associated.\n",
    "\n",
    "The proportion of respondents in each category of a single question is called a marginal proportion. For example, the marginal proportion of the population that has a talent for influencing people is 0.612. We can calculate all the marginal proportions from the contingency table of proportions (saved as influence_leader_prop) using row and column sums as follows:\n",
    "\n",
    "```python\n",
    "leader_marginals = influence_leader_prop.sum(axis=0)\n",
    "print(leader_marginals)\n",
    "influence_marginals =  influence_leader_prop.sum(axis=1)\n",
    "print(influence_marginals)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```bash\n",
    "leader\n",
    "no     0.484365\n",
    "yes    0.515635\n",
    "dtype: float64\n",
    "\n",
    "influence\n",
    "no     0.388213\n",
    "yes    0.611787\n",
    "dtype: float64\n",
    "```\n",
    "\n",
    "While respondents are approximately split on whether they see themselves as a leader, more people think they have a talent for influencing people than not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authority\n",
      "no     0.567541\n",
      "yes    0.432459\n",
      "dtype: float64\n",
      "special\n",
      "no     0.538344\n",
      "yes    0.461656\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# calculate and print authority_marginals\n",
    "authority_marginals = special_authority_prop.sum(axis=0)\n",
    "print(authority_marginals)\n",
    "\n",
    "# calculate and print special_marginals\n",
    "special_marginals =  special_authority_prop.sum(axis=1)\n",
    "print(special_marginals)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Contingency Tables\n",
    "\n",
    "In the previous exercise we calculated the following marginal proportions for the leader and influence questions:\n",
    "\n",
    "```bash\n",
    "leader            influence\n",
    "no     0.484      no     0.388\n",
    "yes    0.516      yes    0.612\n",
    "```\n",
    "\n",
    "In order to understand whether these questions are associated, we can use the marginal proportions to create a contingency table of expected proportions if there were no association between these variables. To calculate these expected proportions, we need to multiply the marginal proportions for each combination of categories:\n",
    "\n",
    "| matrix            | `leader = no`         | `leader = yes`        |\n",
    "| ----------------- | --------------------- | --------------------- |\n",
    "| `influence = no`  | `0.484*0.388 = 0.188` | `0.516*0.388 = .200`  |\n",
    "| `influence = yes` | `0.484*0.612 = 0.296` | `0.516*0.612 = 0.315` |\n",
    "\n",
    "These proportions can then be converted to frequencies by multiplying each one by the sample size (11097 for this data):\n",
    "\n",
    "| matrix            | `leader = no`        | `leader = yes`       |\n",
    "| ----------------- | -------------------- | -------------------- |\n",
    "| `influence = no`  | `0.188*11097 = 2087` | `0.200*11097 = 2221` |\n",
    "| `influence = yes` | `0.296*11097 = 3288` | `0.315*11097 = 3501` |\n",
    "\n",
    "This table tells us that if there were no association between the leader and influence questions, we would expect 2087 people to answer no to both.\n",
    "\n",
    "In python, we can calculate this table using the chi2_contingency() function from SciPy, by passing in the observed frequency table. There are actually four outputs from this function, but for now, we'll only look at the fourth one:\n",
    "\n",
    "```python\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, pval, dof, expected = chi2_contingency(influence_leader_freq)\n",
    "print(np.round(expected))\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```bash\n",
    "[[2087. 2221.]\n",
    " [3288. 3501.]]\n",
    "```\n",
    "\n",
    "Note that the ScyPy function returned the same expected frequencies as we calculated **by hand** above! Now that we have the expected contingency table if there's no association, we can compare it to our observed contingency table:\n",
    "\n",
    "| leader</br>influence | no   | yes  |\n",
    "| -------------------- | ---- | ---- |\n",
    "| no                   | 3015 | 1293 |\n",
    "| yes                  | 2360 | 4429 |\n",
    "\n",
    "The more that the expected and observed tables differ, the more sure we can be that the variables are associated. In this example, we see some pretty big differences (eg., 3015 in the observed table compared to 2087 in the expected table). This provides additional evidence that these variables are associated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed contingency table: \n",
      "authority    no   yes\n",
      "special              \n",
      "no         4069  1905\n",
      "yes        2229  2894\n",
      "expected contingency table (no association):\n",
      " [[3390. 2584.]\n",
      " [2908. 2215.]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "special_authority_freq = pd.crosstab(npi.special, npi.authority)\n",
    "print(f\"observed contingency table: \\n{special_authority_freq}\")\n",
    "\n",
    "# calculate the expected contingency table if there's no association and save it as expected\n",
    "chi2, pval, dof, expected = chi2_contingency(special_authority_freq)\n",
    "\n",
    "# print out the expected frequency table\n",
    "print(f\"expected contingency table (no association):\\n {np.round(expected)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chi-Square Statistic\n",
    "\n",
    "In the previous exercise, we calculated a contingency table of expected frequencies if there were no association between the leader and influence questions. We then compared this to the observed contingency table. Because the tables looked somewhat different, we concluded that responses to these questions are probably associated.\n",
    "\n",
    "While we can inspect these tables visually, many data scientists use the Chi-Square statistic to summarize how different these two tables are. To calculate the Chi Square statistic, we simply find the squared difference between each value in the observed table and its corresponding value in the expected table, and then divide that number by the value from the expected table; finally add up those numbers:\n",
    "\n",
    "```math\n",
    "ChiSquare= âˆ‘(\n",
    "    (observedâˆ’expected)**2 / expected\n",
    " )\n",
    "```\n",
    "\n",
    "The Chi-Square statistic is also the first output of the SciPy function `chi2_contingency()`:\n",
    "\n",
    "```python\n",
    "from scipy.stats import chi2_contingency\n",
    "chi2, pval, dof, expected = chi2_contingency(influence_leader_freq)\n",
    "print(chi2)\n",
    "output: 1307.88\n",
    "```\n",
    "\n",
    "The interpretation of the Chi-Square statistic is dependent on the size of the contingency table. For a 2x2 table (like the one weâ€™ve been investigating), a Chi-Square statistic larger than around 4 would strongly suggest an association between the variables. In this example, our Chi-Square statistic is much larger than that â€” 1307.88! This adds to our evidence that the variables are highly associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679.1219526170606\n"
     ]
    }
   ],
   "source": [
    "# calculate the chi squared statistic and save it as chi2, then print it:\n",
    "chi2, pval, dof, expected = chi2_contingency(special_authority_freq)\n",
    "print(chi2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "In this lesson we used a few different methods to assess whether there was an association between two categorical variables. Although we used binary variables (only 2 options per category), it is important to note that the same techniques can be used for non-binary categorical variables. The methods we used in this lesson included:\n",
    "\n",
    "- Contingency tables of frequencies\n",
    "- Contingency tables of proportions\n",
    "- Marginal proportions\n",
    "- Expected contingency tables\n",
    "- The Chi-Square statistic\n",
    "\n",
    "Note that the data in this lesson was downloaded from [Kaggle](https://www.kaggle.com/lucasgreenwell/narcissistic-personality-inventory-responses), then cleaned and subsetted. The data was originally collected and made public by the [Open-Source Psychometrics Project](https://openpsychometrics.org/).\n",
    "\n",
    "## Instructions\n",
    "\n",
    "As a final exercise, the NPI dataset has been loaded for you once more in script.py as npi. Remember that the columns are defined as follows:\n",
    "\n",
    "- **influence**: `yes` = I have a natural talent for influencing people; `no` = I am not good at influencing people.\n",
    "- **blend_in**: `yes` = I prefer to blend in with the crowd; `no` = I like to be the center of attention.\n",
    "- **special**: `yes` = I think I am a special person; `no` = I am no better or worse than most people.\n",
    "- **leader**: `yes` = I see myself as a good leader; `no` = I am not sure if I would make a good leader.\n",
    "- **authority**: `yes` = I like to have authority over other people; `no` = I don't mind following orders.\n",
    "\n",
    "Which other pairs of questions might be associated (or not)? Use the workspace and your newfound skills to investigate for yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
