{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityU_DataScience_Club_RL_Model\n",
    "\n",
    "For those interested in building a gaming Reinforcement Learning model, here is a sample code.\n",
    "\n",
    "Library versions used are compatible with Python 3.11\n",
    "\n",
    "## Installing OpenAI Gym and Stable Baselines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os\n",
    "\n",
    "# Import the Joypad wrapper\n",
    "# Requires cpp version 14 or later\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "\n",
    "# Import simplified controls for AI to learn faster\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "\n",
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "\n",
    "# Import  Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "from stable_baselines3 import PPO   # algorithm used for training the model\n",
    "\n",
    "# Import Matplotlib to show impact of frame stacking\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Mario game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make(\"SuperMarioBros-v3\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)  # simplifies actions\n",
    "env.action_space\n",
    "\n",
    "env.observation_space\n",
    "print(env.observation_space.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Loop through each frame in the game\n",
    "for frame in range(100000):\n",
    "    if done:\n",
    "        # Start or restart the game\n",
    "        env.reset()\n",
    "    # Pass an action for the game randomly: left, right, etc. from SIMPLE_MOVEMENT\n",
    "    observation, reward, done, info = env.step(env.action_space.sample())\n",
    "    # Show the game on the screen\n",
    "    env.render()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:219: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "c:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:225: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(done, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      9\u001b[0m \u001b[39m# Pass an action for the game randomly: left, right, etc. from SIMPLE_MOVEMENT\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m observation, reward, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(env\u001b[39m.\u001b[39;49maction_space\u001b[39m.\u001b[39;49msample())  \u001b[39m# corrected line\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39m# Show the game on the screen\u001b[39;00m\n\u001b[0;32m     12\u001b[0m env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_action_map[action])\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "# Create a flag- restart or not\n",
    "done = True\n",
    "\n",
    "# Loop through each frame in the game\n",
    "for frame in range(100000):\n",
    "    if done:\n",
    "        # Start or restart the game\n",
    "        env.reset()\n",
    "    # Pass an action for the game randomly: left, right, etc. from SIMPLE_MOVEMENT\n",
    "    obs, reward, done = env.step(env.action_space.sample())  # corrected line\n",
    "    # Show the game on the screen\n",
    "    env.render()\n",
    "\n",
    "# Closes the game\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Environment\n",
    "\n",
    "**`GrayScaleObservation`**\n",
    "  - converts colored frames into grayscale to cut down on computation time and making the training faster\n",
    "\n",
    "\n",
    "**`VecFrameStack`** \n",
    "  - capture several frames while playing the game, vectorize and stack them together. AI will be able to see the actions taken for those frames and learn from them\n",
    "\n",
    "\n",
    "**`DummyVecEnv`**\n",
    "  - wrap stacked frames with the dummy vector environment created for stable baseline and train agent in multiple environments at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Convert to gray scale to minimize data for preprocessing\u001b[39;00m\n\u001b[0;32m     13\u001b[0m env \u001b[39m=\u001b[39m GrayScaleObservation(env, keep_dim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mreset()  \u001b[39m# Here's the additional reset after grayscale conversion\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Show game frame after gray scale conversion\u001b[39;00m\n\u001b[0;32m     17\u001b[0m plt\u001b[39m.\u001b[39mimshow(state)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\core.py:379\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    378\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Resets the environment, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m     obs, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreset(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(obs), info\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup the base environment\n",
    "env = gym_super_mario_bros.make(\"SuperMarioBros-v3\")  # standard version\n",
    "# Simplify the controls or actions\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "\n",
    "state = env.reset()\n",
    "shp = state.shape\n",
    "\n",
    "# Show original game frame\n",
    "plt.imshow(state)\n",
    "\n",
    "# Convert to gray scale to minimize data for preprocessing\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "state = env.reset()  # Here's the additional reset after grayscale conversion\n",
    "\n",
    "# Show game frame after gray scale conversion\n",
    "plt.imshow(state)\n",
    "shp\n",
    "\n",
    "# Wrap inside the Dummy environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "state = env.reset()\n",
    "\n",
    "# Show game frame after dummy environment vectorization\n",
    "plt.imshow(state[0])\n",
    "shp\n",
    "\n",
    "# Stack 4 different frames or images together and apply channel order to last.\n",
    "env = VecFrameStack(env, 4, channels_order=\"last\")\n",
    "state = env.reset()\n",
    "\n",
    "# Show game frame after stacking frames\n",
    "plt.imshow(state[0])\n",
    "shp\n",
    "\n",
    "state, reward, done, info = env.step([env.action_space.sample()])\n",
    "\n",
    "# Show game frame after stacking\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(state.shape[3]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(state[0][:, :, i])\n",
    "plt.show()\n",
    "state = env.reset()\n",
    "\n",
    "SIMPLE_MOVEMENT\n",
    "\n",
    "# run several times to show mario jumping\n",
    "state, reward, done, info = env.step([5])\n",
    "\n",
    "# Show game frame after stacking frames\n",
    "plt.figure(figsize=(20, 16)) \n",
    "for i in range(state.shape[3]):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(state[0][:, :, i])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "JoypadSpace.reset() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Create a Reinforcement Learning AI model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[39m=\u001b[39m PPO(\n\u001b[0;32m      6\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCnnPolicy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     env,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     n_steps\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m model\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m     15\u001b[0m     total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m\n\u001b[0;32m     16\u001b[0m )  \u001b[39m# change to higher value for better results - may take hours without GPU\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:246\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    236\u001b[0m     \u001b[39mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[0;32m    237\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    243\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[0;32m    244\u001b[0m     iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 246\u001b[0m     total_timesteps, callback \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_learn(\n\u001b[0;32m    247\u001b[0m         total_timesteps,\n\u001b[0;32m    248\u001b[0m         callback,\n\u001b[0;32m    249\u001b[0m         reset_num_timesteps,\n\u001b[0;32m    250\u001b[0m         tb_log_name,\n\u001b[0;32m    251\u001b[0m         progress_bar,\n\u001b[0;32m    252\u001b[0m     )\n\u001b[0;32m    254\u001b[0m     callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    256\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:424\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m# pytype: disable=annotation-type-mismatch\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset()  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[39m# pytype: enable=annotation-type-mismatch\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_episode_starts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mnum_envs,), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py:110\u001b[0m, in \u001b[0;36mVecTransposeImage.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[np\u001b[39m.\u001b[39mndarray, Dict]:\n\u001b[0;32m    107\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39m    Reset all environments\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_observations(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvenv\u001b[39m.\u001b[39;49mreset())\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:76\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvObs:\n\u001b[0;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 76\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mreset(seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_seeds[env_idx])\n\u001b[0;32m     77\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     78\u001b[0m     \u001b[39m# Seeds are only used once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected you to pass keyword argument \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m into reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_reset_info[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:112\u001b[0m, in \u001b[0;36mGymV26CompatibilityV0.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreset(seed\u001b[39m=\u001b[39mseed)\n\u001b[0;32m    111\u001b[0m \u001b[39m# Options are ignored\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgym_env\u001b[39m.\u001b[39;49mreset(seed\u001b[39m=\u001b[39;49mseed, options\u001b[39m=\u001b[39;49moptions)\n",
      "File \u001b[1;32mc:\\Users\\Thaddeus Maximus\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\core.py:379\u001b[0m, in \u001b[0;36mObservationWrapper.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreset\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    378\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Resets the environment, returning a modified observation using :meth:`self.observation`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m     obs, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    380\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation(obs), info\n",
      "\u001b[1;31mTypeError\u001b[0m: JoypadSpace.reset() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "# Save training parameters, results, and logs\n",
    "log_path = os.path.join(\"Training\", \"Logs\")\n",
    "\n",
    "# Create a Reinforcement Learning AI model\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=log_path,\n",
    "    learning_rate=0.000001,\n",
    "    n_steps=512,\n",
    ")\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=10000\n",
    ")  # change to higher value for better results - may take hours without GPU\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mario_model_10000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"mario_model_10000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "while True:\n",
    "    actions, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(actions)\n",
    "    env.render()\n",
    "    if done:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
